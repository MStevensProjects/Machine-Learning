{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CazISR8X_HUG"},"source":["# Multiple Linear Regression"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pOyqYHTk_Q57"},"source":["## Importing the libraries"]},{"cell_type":"code","execution_count":132,"metadata":{"colab":{},"colab_type":"code","id":"T_YHJjnD_Tja"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vgC61-ah_WIz"},"source":["## Importing the dataset"]},{"cell_type":"code","execution_count":133,"metadata":{"colab":{},"colab_type":"code","id":"UrxyEKGn_ez7"},"outputs":[],"source":["dataset = pd.read_csv('50_Startups.csv')\n","X = dataset.iloc[:, :-1].values\n","y = dataset.iloc[:, -1].values"]},{"cell_type":"code","execution_count":134,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":857},"colab_type":"code","executionInfo":{"elapsed":552,"status":"ok","timestamp":1586353652778,"user":{"displayName":"Hadelin de Ponteves","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64","userId":"15047218817161520419"},"user_tz":-240},"id":"GOB3QhV9B5kD","outputId":"4a05377a-2db2-43fc-b824-a0710448baee"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[165349.2 136897.8 471784.1 'New York']\n"," [162597.7 151377.59 443898.53 'California']\n"," [153441.51 101145.55 407934.54 'Florida']\n"," [144372.41 118671.85 383199.62 'New York']\n"," [142107.34 91391.77 366168.42 'Florida']\n"," [131876.9 99814.71 362861.36 'New York']\n"," [134615.46 147198.87 127716.82 'California']\n"," [130298.13 145530.06 323876.68 'Florida']\n"," [120542.52 148718.95 311613.29 'New York']\n"," [123334.88 108679.17 304981.62 'California']\n"," [101913.08 110594.11 229160.95 'Florida']\n"," [100671.96 91790.61 249744.55 'California']\n"," [93863.75 127320.38 249839.44 'Florida']\n"," [91992.39 135495.07 252664.93 'California']\n"," [119943.24 156547.42 256512.92 'Florida']\n"," [114523.61 122616.84 261776.23 'New York']\n"," [78013.11 121597.55 264346.06 'California']\n"," [94657.16 145077.58 282574.31 'New York']\n"," [91749.16 114175.79 294919.57 'Florida']\n"," [86419.7 153514.11 0.0 'New York']\n"," [76253.86 113867.3 298664.47 'California']\n"," [78389.47 153773.43 299737.29 'New York']\n"," [73994.56 122782.75 303319.26 'Florida']\n"," [67532.53 105751.03 304768.73 'Florida']\n"," [77044.01 99281.34 140574.81 'New York']\n"," [64664.71 139553.16 137962.62 'California']\n"," [75328.87 144135.98 134050.07 'Florida']\n"," [72107.6 127864.55 353183.81 'New York']\n"," [66051.52 182645.56 118148.2 'Florida']\n"," [65605.48 153032.06 107138.38 'New York']\n"," [61994.48 115641.28 91131.24 'Florida']\n"," [61136.38 152701.92 88218.23 'New York']\n"," [63408.86 129219.61 46085.25 'California']\n"," [55493.95 103057.49 214634.81 'Florida']\n"," [46426.07 157693.92 210797.67 'California']\n"," [46014.02 85047.44 205517.64 'New York']\n"," [28663.76 127056.21 201126.82 'Florida']\n"," [44069.95 51283.14 197029.42 'California']\n"," [20229.59 65947.93 185265.1 'New York']\n"," [38558.51 82982.09 174999.3 'California']\n"," [28754.33 118546.05 172795.67 'California']\n"," [27892.92 84710.77 164470.71 'Florida']\n"," [23640.93 96189.63 148001.11 'California']\n"," [15505.73 127382.3 35534.17 'New York']\n"," [22177.74 154806.14 28334.72 'California']\n"," [1000.23 124153.04 1903.93 'New York']\n"," [1315.46 115816.21 297114.46 'Florida']\n"," [0.0 135426.92 0.0 'California']\n"," [542.05 51743.15 0.0 'New York']\n"," [0.0 116983.8 45173.06 'California']]\n"]}],"source":["print(X)"]},{"cell_type":"code","execution_count":135,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[192261.83 191792.06 191050.39 182901.99 166187.94 156991.12 156122.51\n"," 155752.6  152211.77 149759.96 146121.95 144259.4  141585.52 134307.35\n"," 132602.65 129917.04 126992.93 125370.37 124266.9  122776.86 118474.03\n"," 111313.02 110352.25 108733.99 108552.04 107404.34 105733.54 105008.31\n"," 103282.38 101004.64  99937.59  97483.56  97427.84  96778.92  96712.8\n","  96479.51  90708.19  89949.14  81229.06  81005.76  78239.91  77798.83\n","  71498.49  69758.98  65200.33  64926.08  49490.75  42559.73  35673.41\n","  14681.4 ]\n"]}],"source":["print(y)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VadrvE7s_lS9"},"source":["## Encoding categorical data"]},{"cell_type":"code","execution_count":136,"metadata":{"colab":{},"colab_type":"code","id":"wV3fD1mbAvsh"},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\n","X = np.array(ct.fit_transform(X))"]},{"cell_type":"code","execution_count":137,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":857},"colab_type":"code","executionInfo":{"elapsed":616,"status":"ok","timestamp":1586353657759,"user":{"displayName":"Hadelin de Ponteves","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64","userId":"15047218817161520419"},"user_tz":-240},"id":"4ym3HdYeCGYG","outputId":"ce09e670-cf06-4a1c-f5b0-89422aae0496"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.0 0.0 1.0 165349.2 136897.8 471784.1]\n"," [1.0 0.0 0.0 162597.7 151377.59 443898.53]\n"," [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n"," [0.0 0.0 1.0 144372.41 118671.85 383199.62]\n"," [0.0 1.0 0.0 142107.34 91391.77 366168.42]\n"," [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n"," [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n"," [0.0 1.0 0.0 130298.13 145530.06 323876.68]\n"," [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n"," [1.0 0.0 0.0 123334.88 108679.17 304981.62]\n"," [0.0 1.0 0.0 101913.08 110594.11 229160.95]\n"," [1.0 0.0 0.0 100671.96 91790.61 249744.55]\n"," [0.0 1.0 0.0 93863.75 127320.38 249839.44]\n"," [1.0 0.0 0.0 91992.39 135495.07 252664.93]\n"," [0.0 1.0 0.0 119943.24 156547.42 256512.92]\n"," [0.0 0.0 1.0 114523.61 122616.84 261776.23]\n"," [1.0 0.0 0.0 78013.11 121597.55 264346.06]\n"," [0.0 0.0 1.0 94657.16 145077.58 282574.31]\n"," [0.0 1.0 0.0 91749.16 114175.79 294919.57]\n"," [0.0 0.0 1.0 86419.7 153514.11 0.0]\n"," [1.0 0.0 0.0 76253.86 113867.3 298664.47]\n"," [0.0 0.0 1.0 78389.47 153773.43 299737.29]\n"," [0.0 1.0 0.0 73994.56 122782.75 303319.26]\n"," [0.0 1.0 0.0 67532.53 105751.03 304768.73]\n"," [0.0 0.0 1.0 77044.01 99281.34 140574.81]\n"," [1.0 0.0 0.0 64664.71 139553.16 137962.62]\n"," [0.0 1.0 0.0 75328.87 144135.98 134050.07]\n"," [0.0 0.0 1.0 72107.6 127864.55 353183.81]\n"," [0.0 1.0 0.0 66051.52 182645.56 118148.2]\n"," [0.0 0.0 1.0 65605.48 153032.06 107138.38]\n"," [0.0 1.0 0.0 61994.48 115641.28 91131.24]\n"," [0.0 0.0 1.0 61136.38 152701.92 88218.23]\n"," [1.0 0.0 0.0 63408.86 129219.61 46085.25]\n"," [0.0 1.0 0.0 55493.95 103057.49 214634.81]\n"," [1.0 0.0 0.0 46426.07 157693.92 210797.67]\n"," [0.0 0.0 1.0 46014.02 85047.44 205517.64]\n"," [0.0 1.0 0.0 28663.76 127056.21 201126.82]\n"," [1.0 0.0 0.0 44069.95 51283.14 197029.42]\n"," [0.0 0.0 1.0 20229.59 65947.93 185265.1]\n"," [1.0 0.0 0.0 38558.51 82982.09 174999.3]\n"," [1.0 0.0 0.0 28754.33 118546.05 172795.67]\n"," [0.0 1.0 0.0 27892.92 84710.77 164470.71]\n"," [1.0 0.0 0.0 23640.93 96189.63 148001.11]\n"," [0.0 0.0 1.0 15505.73 127382.3 35534.17]\n"," [1.0 0.0 0.0 22177.74 154806.14 28334.72]\n"," [0.0 0.0 1.0 1000.23 124153.04 1903.93]\n"," [0.0 1.0 0.0 1315.46 115816.21 297114.46]\n"," [1.0 0.0 0.0 0.0 135426.92 0.0]\n"," [0.0 0.0 1.0 542.05 51743.15 0.0]\n"," [1.0 0.0 0.0 0.0 116983.8 45173.06]]\n"]}],"source":["print(X)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WemVnqgeA70k"},"source":["## Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","execution_count":138,"metadata":{"colab":{},"colab_type":"code","id":"Kb_v_ae-A-20"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"k-McZVsQBINc"},"source":["## Training the Multiple Linear Regression model on the Training set"]},{"cell_type":"code","execution_count":139,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":757,"status":"ok","timestamp":1586353664008,"user":{"displayName":"Hadelin de Ponteves","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64","userId":"15047218817161520419"},"user_tz":-240},"id":"ywPjx0L1BMiD","outputId":"099836bc-4d85-4b4f-a488-093faf02e8cb"},"outputs":[{"data":{"text/plain":["LinearRegression()"]},"execution_count":139,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.linear_model import LinearRegression\n","regressor = LinearRegression()\n","regressor.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xNkXL1YQBiBT"},"source":["## Predicting the Test set results"]},{"cell_type":"code","execution_count":140,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":185},"colab_type":"code","executionInfo":{"elapsed":951,"status":"ok","timestamp":1586353666678,"user":{"displayName":"Hadelin de Ponteves","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64","userId":"15047218817161520419"},"user_tz":-240},"id":"TQKmwvtdBkyb","outputId":"493436bf-a4ae-4374-ca16-0b0c25d19457"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[103015.2  103282.38]\n"," [132582.28 144259.4 ]\n"," [132447.74 146121.95]\n"," [ 71976.1   77798.83]\n"," [178537.48 191050.39]\n"," [116161.24 105008.31]\n"," [ 67851.69  81229.06]\n"," [ 98791.73  97483.56]\n"," [113969.44 110352.25]\n"," [167921.07 166187.94]]\n"]}],"source":["y_pred = regressor.predict(X_test)\n","np.set_printoptions(precision=2)\n","print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n","#reshape function allows you to change vector from displaying horizontally by default to vertically with rows of height (len(y_pred)) and a length of 1."]},{"cell_type":"markdown","metadata":{},"source":["## Backward Elimination for Statistical Significance\n","Not required when using scikit learn since applied for you"]},{"cell_type":"code","execution_count":141,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.0 0.0 1.0 165349.2 136897.8 471784.1]\n"," [1.0 0.0 0.0 162597.7 151377.59 443898.53]\n"," [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n"," [0.0 0.0 1.0 144372.41 118671.85 383199.62]\n"," [0.0 1.0 0.0 142107.34 91391.77 366168.42]\n"," [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n"," [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n"," [0.0 1.0 0.0 130298.13 145530.06 323876.68]\n"," [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n"," [1.0 0.0 0.0 123334.88 108679.17 304981.62]\n"," [0.0 1.0 0.0 101913.08 110594.11 229160.95]\n"," [1.0 0.0 0.0 100671.96 91790.61 249744.55]\n"," [0.0 1.0 0.0 93863.75 127320.38 249839.44]\n"," [1.0 0.0 0.0 91992.39 135495.07 252664.93]\n"," [0.0 1.0 0.0 119943.24 156547.42 256512.92]\n"," [0.0 0.0 1.0 114523.61 122616.84 261776.23]\n"," [1.0 0.0 0.0 78013.11 121597.55 264346.06]\n"," [0.0 0.0 1.0 94657.16 145077.58 282574.31]\n"," [0.0 1.0 0.0 91749.16 114175.79 294919.57]\n"," [0.0 0.0 1.0 86419.7 153514.11 0.0]\n"," [1.0 0.0 0.0 76253.86 113867.3 298664.47]\n"," [0.0 0.0 1.0 78389.47 153773.43 299737.29]\n"," [0.0 1.0 0.0 73994.56 122782.75 303319.26]\n"," [0.0 1.0 0.0 67532.53 105751.03 304768.73]\n"," [0.0 0.0 1.0 77044.01 99281.34 140574.81]\n"," [1.0 0.0 0.0 64664.71 139553.16 137962.62]\n"," [0.0 1.0 0.0 75328.87 144135.98 134050.07]\n"," [0.0 0.0 1.0 72107.6 127864.55 353183.81]\n"," [0.0 1.0 0.0 66051.52 182645.56 118148.2]\n"," [0.0 0.0 1.0 65605.48 153032.06 107138.38]\n"," [0.0 1.0 0.0 61994.48 115641.28 91131.24]\n"," [0.0 0.0 1.0 61136.38 152701.92 88218.23]\n"," [1.0 0.0 0.0 63408.86 129219.61 46085.25]\n"," [0.0 1.0 0.0 55493.95 103057.49 214634.81]\n"," [1.0 0.0 0.0 46426.07 157693.92 210797.67]\n"," [0.0 0.0 1.0 46014.02 85047.44 205517.64]\n"," [0.0 1.0 0.0 28663.76 127056.21 201126.82]\n"," [1.0 0.0 0.0 44069.95 51283.14 197029.42]\n"," [0.0 0.0 1.0 20229.59 65947.93 185265.1]\n"," [1.0 0.0 0.0 38558.51 82982.09 174999.3]\n"," [1.0 0.0 0.0 28754.33 118546.05 172795.67]\n"," [0.0 1.0 0.0 27892.92 84710.77 164470.71]\n"," [1.0 0.0 0.0 23640.93 96189.63 148001.11]\n"," [0.0 0.0 1.0 15505.73 127382.3 35534.17]\n"," [1.0 0.0 0.0 22177.74 154806.14 28334.72]\n"," [0.0 0.0 1.0 1000.23 124153.04 1903.93]\n"," [0.0 1.0 0.0 1315.46 115816.21 297114.46]\n"," [1.0 0.0 0.0 0.0 135426.92 0.0]\n"," [0.0 0.0 1.0 542.05 51743.15 0.0]\n"," [1.0 0.0 0.0 0.0 116983.8 45173.06]]\n"]}],"source":["import statsmodels.api as sm\n","#X = np.append(arr = np.ones((50, 1)).astype(int), values = X, axis = 1)\n","#add new column to the array to represent the missing dummy variable that is left out during the Hot Encoding. \n","#This is normally considered b0x0 or the constant as part of the regression equation\n","\n","print(X)"]},{"cell_type":"markdown","metadata":{},"source":["## Backward Elimination Continued"]},{"cell_type":"code","execution_count":143,"metadata":{},"outputs":[{"data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   169.9</td>\n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Tue, 12 Apr 2022</td> <th>  Prob (F-statistic):</th> <td>1.34e-27</td>\n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>04:48:07</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1063.</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>    44</td>      <th>  BIC:               </th> <td>   1074.</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>x1</th> <td> 5.013e+04</td> <td> 6884.820</td> <td>    7.281</td> <td> 0.000</td> <td> 3.62e+04</td> <td>  6.4e+04</td>\n","</tr>\n","<tr>\n","  <th>x2</th> <td> 5.032e+04</td> <td> 7251.767</td> <td>    6.940</td> <td> 0.000</td> <td> 3.57e+04</td> <td> 6.49e+04</td>\n","</tr>\n","<tr>\n","  <th>x3</th> <td> 5.008e+04</td> <td> 6952.587</td> <td>    7.204</td> <td> 0.000</td> <td> 3.61e+04</td> <td> 6.41e+04</td>\n","</tr>\n","<tr>\n","  <th>x4</th> <td>    0.8060</td> <td>    0.046</td> <td>   17.369</td> <td> 0.000</td> <td>    0.712</td> <td>    0.900</td>\n","</tr>\n","<tr>\n","  <th>x5</th> <td>   -0.0270</td> <td>    0.052</td> <td>   -0.517</td> <td> 0.608</td> <td>   -0.132</td> <td>    0.078</td>\n","</tr>\n","<tr>\n","  <th>x6</th> <td>    0.0270</td> <td>    0.017</td> <td>    1.574</td> <td> 0.123</td> <td>   -0.008</td> <td>    0.062</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td>14.782</td> <th>  Durbin-Watson:     </th> <td>   1.283</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.266</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.41e-05</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td> 5.572</td> <th>  Cond. No.          </th> <td>2.45e+06</td>\n","</tr>\n","</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.45e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.951\n","Model:                            OLS   Adj. R-squared:                  0.945\n","Method:                 Least Squares   F-statistic:                     169.9\n","Date:                Tue, 12 Apr 2022   Prob (F-statistic):           1.34e-27\n","Time:                        04:48:07   Log-Likelihood:                -525.38\n","No. Observations:                  50   AIC:                             1063.\n","Df Residuals:                      44   BIC:                             1074.\n","Df Model:                           5                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","x1          5.013e+04   6884.820      7.281      0.000    3.62e+04     6.4e+04\n","x2          5.032e+04   7251.767      6.940      0.000    3.57e+04    6.49e+04\n","x3          5.008e+04   6952.587      7.204      0.000    3.61e+04    6.41e+04\n","x4             0.8060      0.046     17.369      0.000       0.712       0.900\n","x5            -0.0270      0.052     -0.517      0.608      -0.132       0.078\n","x6             0.0270      0.017      1.574      0.123      -0.008       0.062\n","==============================================================================\n","Omnibus:                       14.782   Durbin-Watson:                   1.283\n","Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.266\n","Skew:                          -0.948   Prob(JB):                     2.41e-05\n","Kurtosis:                       5.572   Cond. No.                     2.45e+06\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The condition number is large, 2.45e+06. This might indicate that there are\n","strong multicollinearity or other numerical problems.\n","\"\"\""]},"execution_count":143,"metadata":{},"output_type":"execute_result"}],"source":["X_opt = np.array(X[:, [0, 1, 2, 3, 4, 5]], dtype=float)\n","regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n","regressor_OLS.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['R&D Spend', 'Administration', 'Marketing Spend', 'State', 'Profit']\n","[[1.00e+00 0.00e+00 0.00e+00 1.00e+00 1.65e+05 1.37e+05 4.72e+05]\n"," [1.00e+00 1.00e+00 0.00e+00 0.00e+00 1.63e+05 1.51e+05 4.44e+05]\n"," [1.00e+00 0.00e+00 1.00e+00 0.00e+00 1.53e+05 1.01e+05 4.08e+05]\n"," [1.00e+00 0.00e+00 0.00e+00 1.00e+00 1.44e+05 1.19e+05 3.83e+05]\n"," [1.00e+00 0.00e+00 1.00e+00 0.00e+00 1.42e+05 9.14e+04 3.66e+05]\n"," [1.00e+00 0.00e+00 0.00e+00 1.00e+00 1.32e+05 9.98e+04 3.63e+05]\n"," [1.00e+00 1.00e+00 0.00e+00 0.00e+00 1.35e+05 1.47e+05 1.28e+05]\n"," [1.00e+00 0.00e+00 1.00e+00 0.00e+00 1.30e+05 1.46e+05 3.24e+05]\n"," [1.00e+00 0.00e+00 0.00e+00 1.00e+00 1.21e+05 1.49e+05 3.12e+05]\n"," [1.00e+00 1.00e+00 0.00e+00 0.00e+00 1.23e+05 1.09e+05 3.05e+05]\n"," [1.00e+00 0.00e+00 1.00e+00 0.00e+00 1.02e+05 1.11e+05 2.29e+05]\n"," [1.00e+00 1.00e+00 0.00e+00 0.00e+00 1.01e+05 9.18e+04 2.50e+05]\n"," [1.00e+00 0.00e+00 1.00e+00 0.00e+00 9.39e+04 1.27e+05 2.50e+05]\n"," [1.00e+00 1.00e+00 0.00e+00 0.00e+00 9.20e+04 1.35e+05 2.53e+05]\n"," [1.00e+00 0.00e+00 1.00e+00 0.00e+00 1.20e+05 1.57e+05 2.57e+05]\n"," [1.00e+00 0.00e+00 0.00e+00 1.00e+00 1.15e+05 1.23e+05 2.62e+05]\n"," [1.00e+00 1.00e+00 0.00e+00 0.00e+00 7.80e+04 1.22e+05 2.64e+05]\n"," [1.00e+00 0.00e+00 0.00e+00 1.00e+00 9.47e+04 1.45e+05 2.83e+05]\n"," [1.00e+00 0.00e+00 1.00e+00 0.00e+00 9.17e+04 1.14e+05 2.95e+05]\n"," [1.00e+00 0.00e+00 0.00e+00 1.00e+00 8.64e+04 1.54e+05 0.00e+00]\n"," [1.00e+00 1.00e+00 0.00e+00 0.00e+00 7.63e+04 1.14e+05 2.99e+05]\n"," [1.00e+00 0.00e+00 0.00e+00 1.00e+00 7.84e+04 1.54e+05 3.00e+05]\n"," [1.00e+00 0.00e+00 1.00e+00 0.00e+00 7.40e+04 1.23e+05 3.03e+05]\n"," [1.00e+00 0.00e+00 1.00e+00 0.00e+00 6.75e+04 1.06e+05 3.05e+05]\n"," [1.00e+00 0.00e+00 0.00e+00 1.00e+00 7.70e+04 9.93e+04 1.41e+05]\n"," [1.00e+00 1.00e+00 0.00e+00 0.00e+00 6.47e+04 1.40e+05 1.38e+05]\n"," [1.00e+00 0.00e+00 1.00e+00 0.00e+00 7.53e+04 1.44e+05 1.34e+05]\n"," [1.00e+00 0.00e+00 0.00e+00 1.00e+00 7.21e+04 1.28e+05 3.53e+05]\n"," [1.00e+00 0.00e+00 1.00e+00 0.00e+00 6.61e+04 1.83e+05 1.18e+05]\n"," [1.00e+00 0.00e+00 0.00e+00 1.00e+00 6.56e+04 1.53e+05 1.07e+05]\n"," [1.00e+00 0.00e+00 1.00e+00 0.00e+00 6.20e+04 1.16e+05 9.11e+04]\n"," [1.00e+00 0.00e+00 0.00e+00 1.00e+00 6.11e+04 1.53e+05 8.82e+04]\n"," [1.00e+00 1.00e+00 0.00e+00 0.00e+00 6.34e+04 1.29e+05 4.61e+04]\n"," [1.00e+00 0.00e+00 1.00e+00 0.00e+00 5.55e+04 1.03e+05 2.15e+05]\n"," [1.00e+00 1.00e+00 0.00e+00 0.00e+00 4.64e+04 1.58e+05 2.11e+05]\n"," [1.00e+00 0.00e+00 0.00e+00 1.00e+00 4.60e+04 8.50e+04 2.06e+05]\n"," [1.00e+00 0.00e+00 1.00e+00 0.00e+00 2.87e+04 1.27e+05 2.01e+05]\n"," [1.00e+00 1.00e+00 0.00e+00 0.00e+00 4.41e+04 5.13e+04 1.97e+05]\n"," [1.00e+00 0.00e+00 0.00e+00 1.00e+00 2.02e+04 6.59e+04 1.85e+05]\n"," [1.00e+00 1.00e+00 0.00e+00 0.00e+00 3.86e+04 8.30e+04 1.75e+05]\n"," [1.00e+00 1.00e+00 0.00e+00 0.00e+00 2.88e+04 1.19e+05 1.73e+05]\n"," [1.00e+00 0.00e+00 1.00e+00 0.00e+00 2.79e+04 8.47e+04 1.64e+05]\n"," [1.00e+00 1.00e+00 0.00e+00 0.00e+00 2.36e+04 9.62e+04 1.48e+05]\n"," [1.00e+00 0.00e+00 0.00e+00 1.00e+00 1.55e+04 1.27e+05 3.55e+04]\n"," [1.00e+00 1.00e+00 0.00e+00 0.00e+00 2.22e+04 1.55e+05 2.83e+04]\n"," [1.00e+00 0.00e+00 0.00e+00 1.00e+00 1.00e+03 1.24e+05 1.90e+03]\n"," [1.00e+00 0.00e+00 1.00e+00 0.00e+00 1.32e+03 1.16e+05 2.97e+05]\n"," [1.00e+00 1.00e+00 0.00e+00 0.00e+00 0.00e+00 1.35e+05 0.00e+00]\n"," [1.00e+00 0.00e+00 0.00e+00 1.00e+00 5.42e+02 5.17e+04 0.00e+00]\n"," [1.00e+00 1.00e+00 0.00e+00 0.00e+00 0.00e+00 1.17e+05 4.52e+04]]\n"]}],"source":["header = []\n","i=0\n","#for row in dataset:\n","#    header.append(row)\n","for row in dataset:\n","    if i < 5:\n","        header.append(row)\n","        i+=1\n","    \n","print(header)\n","print(X_opt)"]},{"cell_type":"markdown","metadata":{},"source":["## Remove index with P Value above Significance Level"]},{"cell_type":"code","execution_count":144,"metadata":{},"outputs":[{"data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.948</td>\n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.943</td>\n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   205.0</td>\n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Tue, 12 Apr 2022</td> <th>  Prob (F-statistic):</th> <td>2.90e-28</td>\n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>04:48:24</td>     <th>  Log-Likelihood:    </th> <td> -526.75</td>\n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1064.</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1073.</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>x1</th> <td>  5.46e+04</td> <td> 6371.060</td> <td>    8.571</td> <td> 0.000</td> <td> 4.18e+04</td> <td> 6.74e+04</td>\n","</tr>\n","<tr>\n","  <th>x2</th> <td>  5.57e+04</td> <td> 6502.532</td> <td>    8.565</td> <td> 0.000</td> <td> 4.26e+04</td> <td> 6.88e+04</td>\n","</tr>\n","<tr>\n","  <th>x3</th> <td> 5.457e+04</td> <td> 6445.883</td> <td>    8.465</td> <td> 0.000</td> <td> 4.16e+04</td> <td> 6.75e+04</td>\n","</tr>\n","<tr>\n","  <th>x4</th> <td>    0.8609</td> <td>    0.031</td> <td>   27.665</td> <td> 0.000</td> <td>    0.798</td> <td>    0.924</td>\n","</tr>\n","<tr>\n","  <th>x5</th> <td>   -0.0527</td> <td>    0.050</td> <td>   -1.045</td> <td> 0.301</td> <td>   -0.154</td> <td>    0.049</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td>14.275</td> <th>  Durbin-Watson:     </th> <td>   1.197</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  19.260</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td>-0.953</td> <th>  Prob(JB):          </th> <td>6.57e-05</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td> 5.369</td> <th>  Cond. No.          </th> <td>1.15e+06</td>\n","</tr>\n","</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.15e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.948\n","Model:                            OLS   Adj. R-squared:                  0.943\n","Method:                 Least Squares   F-statistic:                     205.0\n","Date:                Tue, 12 Apr 2022   Prob (F-statistic):           2.90e-28\n","Time:                        04:48:24   Log-Likelihood:                -526.75\n","No. Observations:                  50   AIC:                             1064.\n","Df Residuals:                      45   BIC:                             1073.\n","Df Model:                           4                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","x1           5.46e+04   6371.060      8.571      0.000    4.18e+04    6.74e+04\n","x2           5.57e+04   6502.532      8.565      0.000    4.26e+04    6.88e+04\n","x3          5.457e+04   6445.883      8.465      0.000    4.16e+04    6.75e+04\n","x4             0.8609      0.031     27.665      0.000       0.798       0.924\n","x5            -0.0527      0.050     -1.045      0.301      -0.154       0.049\n","==============================================================================\n","Omnibus:                       14.275   Durbin-Watson:                   1.197\n","Prob(Omnibus):                  0.001   Jarque-Bera (JB):               19.260\n","Skew:                          -0.953   Prob(JB):                     6.57e-05\n","Kurtosis:                       5.369   Cond. No.                     1.15e+06\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The condition number is large, 1.15e+06. This might indicate that there are\n","strong multicollinearity or other numerical problems.\n","\"\"\""]},"execution_count":144,"metadata":{},"output_type":"execute_result"}],"source":["X_opt = np.array(X[:, [0, 1, 2, 3, 4]], dtype=float)\n","regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n","regressor_OLS.summary()"]},{"cell_type":"code","execution_count":146,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['R&D Spend', 'Administration', 'Marketing Spend', 'State', 'Profit']\n"]}],"source":["print(header)"]},{"cell_type":"code","execution_count":145,"metadata":{},"outputs":[{"data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.947</td>\n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.943</td>\n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   272.4</td>\n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Tue, 12 Apr 2022</td> <th>  Prob (F-statistic):</th> <td>2.76e-29</td>\n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>04:48:40</td>     <th>  Log-Likelihood:    </th> <td> -527.35</td>\n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1063.</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1070.</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>x1</th> <td> 4.875e+04</td> <td> 3040.118</td> <td>   16.036</td> <td> 0.000</td> <td> 4.26e+04</td> <td> 5.49e+04</td>\n","</tr>\n","<tr>\n","  <th>x2</th> <td> 4.991e+04</td> <td> 3422.664</td> <td>   14.584</td> <td> 0.000</td> <td>  4.3e+04</td> <td> 5.68e+04</td>\n","</tr>\n","<tr>\n","  <th>x3</th> <td> 4.876e+04</td> <td> 3275.140</td> <td>   14.888</td> <td> 0.000</td> <td> 4.22e+04</td> <td> 5.54e+04</td>\n","</tr>\n","<tr>\n","  <th>x4</th> <td>    0.8530</td> <td>    0.030</td> <td>   28.226</td> <td> 0.000</td> <td>    0.792</td> <td>    0.914</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td>13.418</td> <th>  Durbin-Watson:     </th> <td>   1.122</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  17.605</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td>-0.907</td> <th>  Prob(JB):          </th> <td>0.000150</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td> 5.271</td> <th>  Cond. No.          </th> <td>2.90e+05</td>\n","</tr>\n","</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.9e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.947\n","Model:                            OLS   Adj. R-squared:                  0.943\n","Method:                 Least Squares   F-statistic:                     272.4\n","Date:                Tue, 12 Apr 2022   Prob (F-statistic):           2.76e-29\n","Time:                        04:48:40   Log-Likelihood:                -527.35\n","No. Observations:                  50   AIC:                             1063.\n","Df Residuals:                      46   BIC:                             1070.\n","Df Model:                           3                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","x1          4.875e+04   3040.118     16.036      0.000    4.26e+04    5.49e+04\n","x2          4.991e+04   3422.664     14.584      0.000     4.3e+04    5.68e+04\n","x3          4.876e+04   3275.140     14.888      0.000    4.22e+04    5.54e+04\n","x4             0.8530      0.030     28.226      0.000       0.792       0.914\n","==============================================================================\n","Omnibus:                       13.418   Durbin-Watson:                   1.122\n","Prob(Omnibus):                  0.001   Jarque-Bera (JB):               17.605\n","Skew:                          -0.907   Prob(JB):                     0.000150\n","Kurtosis:                       5.271   Cond. No.                     2.90e+05\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The condition number is large, 2.9e+05. This might indicate that there are\n","strong multicollinearity or other numerical problems.\n","\"\"\""]},"execution_count":145,"metadata":{},"output_type":"execute_result"}],"source":["X_opt = np.array(X[:, [0, 1, 2, 3]], dtype=float)\n","regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n","regressor_OLS.summary()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPhYhte6t7H4wEK4xPpDWT7","name":"Multiple Linear Regression","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}
